import { createEndpointAdapter } from '@/lib/adapters';
import { ketch } from '@/lib/browser';
import type { ChatCompletionRequest, StructuredAIResponse } from '@/lib/endpoint-adapter';
import { isDev, isProd } from '@/lib/global';
import { AnyChatHistory, ChatHistory, ChatMessage, OPENAI_MODELS } from '@/lib/static';
import { ReasoningEffortType, VerbosityType } from '@/schema/ai';
import { AiProviderType } from '@/schema/plugin-config';
import { marked } from 'marked';
import { nanoid } from 'nanoid';
import { z } from 'zod';

export const migrateChatHistory = (chatHistory: AnyChatHistory): ChatHistory => {
  switch (chatHistory.version) {
    case undefined:
    case 1:
      return migrateChatHistory({ ...chatHistory, version: 2, iconUrl: '' });
    case 2:
      return migrateChatHistory({
        ...chatHistory,
        version: 3,
        aiModel: OPENAI_MODELS[0],
        temperature: 0.7,
        maxTokens: 0,
      });
    case 3:
      return migrateChatHistory({ ...chatHistory, version: 4 });
    case 4:
      return migrateChatHistory({
        ...chatHistory,
        version: 5,
        messages: chatHistory.messages.map((m) => ({ ...m, id: nanoid() })),
      });
    case 5:
      return migrateChatHistory({
        ...chatHistory,
        version: 6,
        verbosity: 'medium',
        reasoningEffort: 'low',
      });
    case 6:
      const { aiModel, temperature, maxTokens, iconUrl, verbosity, reasoningEffort, ...rest } =
        chatHistory;
      return migrateChatHistory({
        ...rest,
        version: 7,
        assistantId: '',
      });
    case 7:
      return migrateChatHistory({
        ...chatHistory,
        version: 8,
      });
    case 8:
      return migrateChatHistory({
        ...chatHistory,
        version: 9,
        html: undefined,
      });
    case 9:
    default:
      return chatHistory;
  }
};

export const createNewChatHistory = (params: Omit<ChatHistory, 'version'>): ChatHistory => {
  return { version: 9, ...params };
};

/**
 * AIãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‹å®šç¾©
 */
export type AICompletionParams = {
  model: string;
  temperature: number;
  maxTokens: number;
  messages: ChatMessage[];
  systemPrompt?: string;
  providerType?: AiProviderType;
  verbosity?: VerbosityType;
  reasoningEffort?: ReasoningEffortType;
  webSearchEnabled?: boolean;
  promptId?: string;
  imageGenerationEnabled?: boolean;
  htmlOutputEnabled?: boolean;
  currentHtml?: string;
};

/**
 * AI APIã‚’å‘¼ã³å‡ºã—ã€Structured Outputã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦è¿”ã™
 * @template T Zodã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰æ¨è«–ã•ã‚Œã‚‹å‹
 * @param params ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
 * @param schema Zodã‚¹ã‚­ãƒ¼ãƒï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å®šç¾©ï¼‰
 * @returns æ­£è¦åŒ–ã•ã‚ŒãŸAIãƒ¬ã‚¹ãƒãƒ³ã‚¹
 */
export async function fetchAICompletion<T>(
  params: AICompletionParams,
  schema: z.ZodType<T>
): Promise<StructuredAIResponse<T>> {
  const {
    model,
    temperature,
    maxTokens,
    messages,
    systemPrompt,
    providerType = 'openai',
    verbosity = 'medium',
    reasoningEffort = 'low',
    webSearchEnabled = false,
    promptId,
    imageGenerationEnabled = false,
    htmlOutputEnabled = false,
    currentHtml,
  } = params;

  const logTitle = `ğŸ§  AI API call`;
  isDev && console.time(logTitle);

  // ã‚¢ãƒ€ãƒ—ã‚¿ã®ç”Ÿæˆ
  const adapter = createEndpointAdapter(providerType);

  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ§‹ç¯‰
  const request: ChatCompletionRequest = {
    model,
    temperature,
    maxTokens,
    messages,
    systemPrompt,
    verbosity,
    reasoningEffort,
    webSearchEnabled,
    promptId,
    imageGenerationEnabled,
    htmlOutputEnabled,
    currentHtml,
    schema,
  };

  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®æ§‹ç¯‰ï¼ˆã‚¢ãƒ€ãƒ—ã‚¿ã«å§”è­²ï¼‰
  const payload = adapter.buildRequestPayload(request);

  isDev &&
    console.log(`${logTitle} - API Request`, {
      endpoint: adapter.endpoint,
      providerType,
      payload,
    });

  // APIå‘¼ã³å‡ºã—
  const response = await ketch(adapter.endpoint, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(payload),
  });

  !isProd && console.timeEnd(logTitle);

  const apiResponse = await response.json();

  !isProd &&
    console.log(`${logTitle} - API Response`, {
      responseBody: apiResponse,
      responseCode: response.status,
      responseHeader: response.headers,
    });

  // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚¢ãƒ€ãƒ—ã‚¿ã«å§”è­²ï¼‰
  const result = await adapter.parseResponse(response, apiResponse, schema);

  isDev && console.log(`ã“ã®ã‚„ã‚Šå–ã‚Šã§${result.usage?.totalTokens ?? 'ä¸æ˜'}ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã—ã¾ã—ãŸ`);

  return result;
}

export const getHTMLfromMarkdown = (markdown: string): string => {
  return marked(markdown, { async: false }) as string;
};

export const getChatTitle = (message: ChatMessage): string => {
  // ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å¯¾è±¡å¤–
  if (message.role === 'fact-check') {
    return 'ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯';
  }
  const { content } = message;
  if (!content) {
    return 'ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸';
  }
  if (typeof content === 'string') {
    return content.slice(0, 16);
  }
  const found = content.find((m) => m.type === 'text') as any | undefined;
  return (found?.text ?? 'ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸').slice(0, 16);
};
